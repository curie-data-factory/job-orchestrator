{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Guide Utilisateur Qu'est ce que c'est ? Job Orchestrator est un outil qui permet de centraliser toutes les activit\u00e9s de processing de la direction des data de l'Institut Curie. C'est une interface qui permet de communiquer avec les diff\u00e9rents composants de la chaine de traitement des donn\u00e9es de l'Institut Curie. Aper\u00e7u & Mannuel d'utilisation Page de Connexion La page de connexion utilise la connexion LDAP, seul les personnes de la direction des donn\u00e9es peuvent se connecter sur ce service. Page de listing des r\u00e9pertoires La page de listing des r\u00e9pertoires Nexus permet de selectionner un r\u00e9pertoire Nexus sur lequel on a t\u00e9l\u00e9charg\u00e9 nos ressources \u00e0 executer. On peut rechercher dans le r\u00e9pertoire Nexus selectionn\u00e9 pour affiner sa recherche. On peut cliquer sur le bouton correspondant \u00e0 la version du binaire \u00e0 executer. Qui nous permettra de configurer le contexte d'execution de notre ressource sur le cluster. Configuration du contexte d'execution La page de configuration permet de d\u00e9finir les options de configuration pour l'execution de notre ressource. Elle est d\u00e9coup\u00e9 en plusieurs parties : 1. Ressource to Run The resources to run is the package or compiled runnable file that you want to execute. Basically it's your job. It has a generated job name that you can edit. You can select the exact Nexus resource to run just bellow. 2. Runner The runner is the docker container in which your job will run. Be careful to choose a container that fits your executable requirements. 3. Runner Configuration The runner configuration is all the settings around the container. It lets you set up CRON scheduling, mounting points etc... 4. Deploy When executing the deployment,a Kubernetes resource will be created and all the configurations will be applied. It will then run the chosen container. In the container, it will mount the CIFS volume if configured and pull the Nexus resource. It will then execute the resource. Cas Pratique Dans le cas pratique d'un d\u00e9veloppement d'un job ETL Talend: nous allons d\u00e9velopper notre job ETL sur notre ordinateur, puis, commit/push sur notre r\u00e9pository GitLab, gr\u00e2ce au build/test automatique il va build et envoyer le job finalement test\u00e9 et packag\u00e9 sur Nexus. Une fois acc\u00e9ssible sur le r\u00e9pertoire Nexus, nous pouvons selectionner le job et enfin configurer son lancement sur l'environnement de production. Et voila ! Listing jobs Afin de v\u00e9rifier la bonne execution des jobs, nous pouvons aller dans l'interface de listing des jobs. Nous pouvons visualiser : la date de d\u00e9ploiement l'\u00e9tat du d\u00e9ploiement (Active/Inactive) l'\u00e9tat de fonctionnement des containers (Scheduled/Initiated/Running/Failed/Stopped) Le nom du job. V\u00e9rifier l'image utilis\u00e9 pour executer la ressource. La ressource sp\u00e9cifiquement utilis\u00e9 pour l'execution. Le Type de job (job/CronJob) Pour un CronJob on peut voir la fr\u00e9quence de lancement (Schedule) Pour un CronJob on peut voir la date de derni\u00e8re execution du job. Nous pouvons voir les logs du job ou du lancement de job le plus r\u00e9cent pour les cronJob. Nous pouvons avoir une traduction de notre job en t\u00e2che Airflow. Nous pouvons supprimer le d\u00e9ploiement. Apache Airflow Nous avons int\u00e9gr\u00e9 la possibilit\u00e9 de pouvoir consulter les jobs Apache Airflow. Apache airflow est un outil qui permet d'orchestrer des pipelines data. Il nous permet de suivre l'\u00e9volution de nos pipelines de donn\u00e9es, ainsi que d'en assurer la maintenance si besoin. Gitlabmonitor Gitlabmonitor est un outil qui permet de visualiser les pipelines de CI/CD qui s'executent \u00e0 partir de Gitlab Nexus Finalement il y a \u00e9galement \u00e0 disposition un lien pour aller sur Nexus pour voir les ressources directement dans les r\u00e9pertoires. Spark Il y a \u00e9galement il liens vers l'interface Spark pour pouvoir visualiser les jobs qui tournent sur l'environnement Spark.","title":"Home"},{"location":"index.html#guide-utilisateur","text":"","title":"Guide Utilisateur"},{"location":"index.html#quest-ce-que-cest","text":"Job Orchestrator est un outil qui permet de centraliser toutes les activit\u00e9s de processing de la direction des data de l'Institut Curie. C'est une interface qui permet de communiquer avec les diff\u00e9rents composants de la chaine de traitement des donn\u00e9es de l'Institut Curie.","title":"Qu'est ce que c'est ?"},{"location":"index.html#apercu-mannuel-dutilisation","text":"","title":"Aper\u00e7u &amp; Mannuel d'utilisation"},{"location":"index.html#page-de-connexion","text":"La page de connexion utilise la connexion LDAP, seul les personnes de la direction des donn\u00e9es peuvent se connecter sur ce service.","title":"Page de Connexion"},{"location":"index.html#page-de-listing-des-repertoires","text":"La page de listing des r\u00e9pertoires Nexus permet de selectionner un r\u00e9pertoire Nexus sur lequel on a t\u00e9l\u00e9charg\u00e9 nos ressources \u00e0 executer. On peut rechercher dans le r\u00e9pertoire Nexus selectionn\u00e9 pour affiner sa recherche. On peut cliquer sur le bouton correspondant \u00e0 la version du binaire \u00e0 executer. Qui nous permettra de configurer le contexte d'execution de notre ressource sur le cluster.","title":"Page de listing des r\u00e9pertoires"},{"location":"index.html#configuration-du-contexte-dexecution","text":"La page de configuration permet de d\u00e9finir les options de configuration pour l'execution de notre ressource. Elle est d\u00e9coup\u00e9 en plusieurs parties : 1. Ressource to Run The resources to run is the package or compiled runnable file that you want to execute. Basically it's your job. It has a generated job name that you can edit. You can select the exact Nexus resource to run just bellow. 2. Runner The runner is the docker container in which your job will run. Be careful to choose a container that fits your executable requirements. 3. Runner Configuration The runner configuration is all the settings around the container. It lets you set up CRON scheduling, mounting points etc... 4. Deploy When executing the deployment,a Kubernetes resource will be created and all the configurations will be applied. It will then run the chosen container. In the container, it will mount the CIFS volume if configured and pull the Nexus resource. It will then execute the resource.","title":"Configuration du contexte d'execution"},{"location":"index.html#cas-pratique","text":"Dans le cas pratique d'un d\u00e9veloppement d'un job ETL Talend: nous allons d\u00e9velopper notre job ETL sur notre ordinateur, puis, commit/push sur notre r\u00e9pository GitLab, gr\u00e2ce au build/test automatique il va build et envoyer le job finalement test\u00e9 et packag\u00e9 sur Nexus. Une fois acc\u00e9ssible sur le r\u00e9pertoire Nexus, nous pouvons selectionner le job et enfin configurer son lancement sur l'environnement de production. Et voila !","title":"Cas Pratique"},{"location":"index.html#listing-jobs","text":"Afin de v\u00e9rifier la bonne execution des jobs, nous pouvons aller dans l'interface de listing des jobs. Nous pouvons visualiser : la date de d\u00e9ploiement l'\u00e9tat du d\u00e9ploiement (Active/Inactive) l'\u00e9tat de fonctionnement des containers (Scheduled/Initiated/Running/Failed/Stopped) Le nom du job. V\u00e9rifier l'image utilis\u00e9 pour executer la ressource. La ressource sp\u00e9cifiquement utilis\u00e9 pour l'execution. Le Type de job (job/CronJob) Pour un CronJob on peut voir la fr\u00e9quence de lancement (Schedule) Pour un CronJob on peut voir la date de derni\u00e8re execution du job. Nous pouvons voir les logs du job ou du lancement de job le plus r\u00e9cent pour les cronJob. Nous pouvons avoir une traduction de notre job en t\u00e2che Airflow. Nous pouvons supprimer le d\u00e9ploiement.","title":"Listing jobs"},{"location":"index.html#apache-airflow","text":"Nous avons int\u00e9gr\u00e9 la possibilit\u00e9 de pouvoir consulter les jobs Apache Airflow. Apache airflow est un outil qui permet d'orchestrer des pipelines data. Il nous permet de suivre l'\u00e9volution de nos pipelines de donn\u00e9es, ainsi que d'en assurer la maintenance si besoin.","title":"Apache Airflow"},{"location":"index.html#gitlabmonitor","text":"Gitlabmonitor est un outil qui permet de visualiser les pipelines de CI/CD qui s'executent \u00e0 partir de Gitlab","title":"Gitlabmonitor"},{"location":"index.html#nexus","text":"Finalement il y a \u00e9galement \u00e0 disposition un lien pour aller sur Nexus pour voir les ressources directement dans les r\u00e9pertoires.","title":"Nexus"},{"location":"index.html#spark","text":"Il y a \u00e9galement il liens vers l'interface Spark pour pouvoir visualiser les jobs qui tournent sur l'environnement Spark.","title":"Spark"}]}